#!/usr/local/bin/python3

import argparse
import json

import bibtexparser
import requests
import sys
import os

import time
from bibtexparser.bwriter import BibTexWriter

from crossref.restful import Works
works = Works()

BIB_CACHE_FILE_PATH = "/tmp/fix-bibtex.bib.cache"
TITLE_CACHE_FILE_PATH = "/tmp/fix-bibtex.title.cache"


def doi2bib(doi, cache):
    """
    Return a bibTeX string of metadata for a given DOI.
    Reference: https://gist.github.com/jrsmith3/5513926
    """

    if doi in cache:
        return cache[doi]

    url = "http://dx.doi.org/" + doi

    headers = {"accept": "application/x-bibtex"}
    r = requests.get(url, headers=headers)

    cache[doi] = r.text
    return r.text


MAX_RETRY = 10


def safe_doi2bib(doi, cache):
    for i in range(MAX_RETRY):
        result = doi2bib(doi, cache)
        if result != '' and result is not None:
            return result
        time.sleep(1)

    print("timeout")

#%%
def find_by_title(title, cache):
    if(title in cache):
        return cache[title]
    res = works.query(title).sort('score')

    res.sample(1)

    first_result = None
    for i in res:
        first_result = i
        break

    result_title = first_result['title'][0]

    print("original: " + title)
    print("found: " + result_title)

    user_input = 'a'

    while user_input not in 'ny':
        print("y/n?")
        user_input = sys.stdin.read(1)[0]
        print(user_input)

    doi_result = None
    if user_input == 'y':
        doi_result = first_result["DOI"]

    cache[title] = doi_result
    return doi_result
#%%


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Fix BibTex File generated by ReadCube")
    parser.add_argument('bibtex_file', metavar='FILE', type=str, help='BibTex file generated by ReadCube for fixing')
    parser.add_argument('--out', dest='output_bibtex_file', metavar='OUTPUT', type=str, help='output file location',
                        required=True)
    args = parser.parse_args()
    if os.path.exists(BIB_CACHE_FILE_PATH):
        with open(BIB_CACHE_FILE_PATH) as cache_file:
            bib_cache = json.load(cache_file)
    else:
        bib_cache = dict()

    args = parser.parse_args()
    if os.path.exists(TITLE_CACHE_FILE_PATH):
        with open(TITLE_CACHE_FILE_PATH) as cache_file:
            title_cache = json.load(cache_file)
    else:
        title_cache = dict()

    with open(args.bibtex_file) as bibtex_file:
        bib_database = bibtexparser.load(bibtex_file)
    print('%d BibTex entries loaded!' % len(bib_database.entries), file=sys.stderr)
    i = 1
    j = 1
    for bib_entry in bib_database.entries:
        doi = None
        if 'doi' in bib_entry:
            doi = bib_entry['doi']
        else:
            doi = find_by_title(bib_entry['title'], title_cache)
        if doi is not None:
            new_bibtex = safe_doi2bib(doi, bib_cache)
            parsed_entries = bibtexparser.loads(new_bibtex).entries
            if len(parsed_entries) > 0:
                new_bib_entry = parsed_entries[0]
                new_bib_entry['ID'] = bib_entry['ID']
                bib_database.entries_dict[new_bib_entry['ID']] = new_bib_entry
                print('%d / %d BibTex entries fixed!' % (i, j), file=sys.stderr)
            else:
                print("parse failed")
                print(doi)
                print(new_bibtex)
            i += 1
        j += 1
        with open(BIB_CACHE_FILE_PATH, 'w') as cache_file:
            json.dump(bib_cache, cache_file)
        with open(TITLE_CACHE_FILE_PATH, 'w') as cache_file:
            json.dump(title_cache, cache_file)

    bib_database.entries = [value for key, value in bib_database.entries_dict.items()]

    with open(args.output_bibtex_file, 'w') as bibtex_file:
        bibtex_file.write(BibTexWriter().write(bib_database))

#%%
#print(find_by_title('Your location has been shared 5,398 times!: A field study on mobile app privacy nudging'))


#%%

